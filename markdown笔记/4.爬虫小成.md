1.完成目标二， 爬虫小成；

2.附带任务： 将所爬数据存入数据库

```python
import requests
from bs4 import BeautifulSoup
import time
import pymysql
from datetime import datetime


def createDatebase(cursor):
    sql1 = 'drop database if exists `cjx`;'
    sql2 = 'create database `cjx`;'
    sql3 = """CREATE TABLE `cjx`.`comments` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `author` varchar(30) NOT NULL DEFAULT 'cjx小可爱' COMMENT '评论作者',
  `commented_at` timestamp NOT NULL DEFAULT '2019-10-30 00:00:00' COMMENT '评论时间',
  `content` varchar(255) NOT NULL DEFAULT 'cjx 小猪猪 love liyi 大猪猪' COMMENT '评论内容',
  `created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=11 DEFAULT CHARSET=utf8mb4 COMMENT='cjx小可爱需要的评论表';
        """
    cursor.execute(sql1)
    cursor.execute(sql2)
    cursor.execute(sql3)


def getCommentDetail(url):
    """
    获取指定页面的评论列表
    :param url: 指定url
    :return: comments = [author, time, content]
    """

    comments = []

    res = requests.get(url)
    if res.status_code != 200:
        return []

    soup = BeautifulSoup(res.text, 'html.parser')
    for li in soup.select('.comment-list li'):
        author = li.b.text
        time = li.time.text.strip()
        content = li.p.text.strip()
        comment = [author, time, content]
        comments.append(comment)

    return comments


def getCommentsList():
    baseurl = 'https://wordpress-edu-3autumn.localprod.oc.forchange.cn/all-about-' \
              'the-future_04/comment-page-{0}/'

    pageNum = 1
    result = []
    while True:
        url = baseurl.format(pageNum)
        tmp_result = getCommentDetail(url)
        if (not tmp_result) or (pageNum == 2):
            # tmp_result为空
            break

        result += tmp_result
        pageNum += 1

    return result, pageNum


def getConnect():
    return pymysql.connect(
        host='localhost',
        user='root',
        password='123456',
        #database='cjx'
    )


def main():
    getConnect()
    # 多页评论
    start = time.time()
    total_comments, page = getCommentsList()
    end = time.time()
    print('爬取了{page}页评论, 共花费{time_cost}秒'.format(page=page, time_cost=end - start))
    # 连接数据库， 仅连接到具体host， 没有连接到具体数据库
    conn = getConnect()
    cursor = conn.cursor()
    # 建立数据库和数据表
    createDatebase(cursor)

    # 插入数据
    for index, comments in enumerate(total_comments):
        print(comments)
        author, commented_at, content = comments
        sql = """
            insert into `cjx`.`comments` (author, commented_at, content) 
            values('{author}', '{commented_at}', '{content}')
        """.format(
            author=author,
            commented_at=commented_at,
            content=content
        )
        print(sql)
        cursor.execute(sql)

    # 查询
    sql = 'select * from `cjx`.`comments`'
    cursor.execute(sql)
    # 获取所有记录
    comments = cursor.fetchall()
    print(comments)


if __name__ == '__main__':
    main()

```

